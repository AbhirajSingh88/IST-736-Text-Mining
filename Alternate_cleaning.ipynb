{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Text Mining\\PROJECT\n"
     ]
    }
   ],
   "source": [
    "cd \"E:\\Text Mining\\PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import numpy as np\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanTweet(text):\n",
    "    tok = WordPunctTokenizer()\n",
    "    user_pattern = '@[A-Za-z0-9_]+'\n",
    "    http_pattern = 'https?://[^ ]+'\n",
    "    www_pattern = 'www.[^ ]+'\n",
    "    combined_pattern = '|'.join((user_pattern, http_pattern, www_pattern))\n",
    "    negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                    \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                    \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                    \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                    \"mustn't\":\"must not\"}\n",
    "    neg_pattern = re.compile('\\b(' + '|'.join(negations_dic.keys()) + ')\\b')\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pattern, '', bom_removed)\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], stripped)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled).lower()\n",
    "    cleaned = (\" \".join(x for x in tok.tokenize(letters_only) if len(x) > 1)).strip()\n",
    "    cleaned = ''.join(k + k if sum(1 for i in g) > 1 else k for k, g in itertools.groupby(cleaned))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:294: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 7 columns):\n",
      "target        1600000 non-null int64\n",
      "ids           1600000 non-null int64\n",
      "date          1600000 non-null object\n",
      "flag          1600000 non-null object\n",
      "user          1600000 non-null object\n",
      "text          1600000 non-null object\n",
      "clean_text    1600000 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 85.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = p.read_csv(\"tweet.csv\", encoding=\"latin-1\", names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "data['clean_text'] = [getCleanTweet(text) for text in data['text']]\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = data['clean_text'].values\n",
    "y_values = data['target'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_values, y_values, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120000, 40537)\n",
      "(480000, 40537)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer(encoding='latin-1',binary=False,min_df = 5 ,stop_words='english')\n",
    "bi_vector = CountVectorizer(encoding='latin-1',stop_words='english',binary=False, ngram_range=(1,2),min_df = 5)\n",
    "\n",
    "x_train_vec = vector.fit_transform(x_train)\n",
    "print(x_train_vec.shape)\n",
    "\n",
    "x_test_vec = vector.transform(x_test)\n",
    "print(x_test_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7724708333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC as svm\n",
    "svm = svm(C=1, max_iter=1000)\n",
    "svm.fit(x_train_vec,y_train)\n",
    "svm.score(x_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
