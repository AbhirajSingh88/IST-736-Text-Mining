{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Random_forest.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilL73Gt5MXg1",
        "colab_type": "code",
        "outputId": "80328d85-2d69-4978-ddb6-2333b405c5e3",
        "colab": {}
      },
      "source": [
        "cd \"E:\\Text Mining\\PROJECT\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E:\\Text Mining\\PROJECT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHY4u7mjMXhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as p\n",
        "import numpy as np\n",
        "import itertools\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRtM6DYHMXhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getCleanTweet(text):\n",
        "    tok = WordPunctTokenizer()\n",
        "    user_pattern = '@[A-Za-z0-9_]+'\n",
        "    http_pattern = 'https?://[^ ]+'\n",
        "    www_pattern = 'www.[^ ]+'\n",
        "    combined_pattern = '|'.join((user_pattern, http_pattern, www_pattern))\n",
        "    negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
        "                    \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                    \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                    \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                    \"mustn't\":\"must not\"}\n",
        "    neg_pattern = re.compile('\\b(' + '|'.join(negations_dic.keys()) + ')\\b')\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        bom_removed = souped\n",
        "    stripped = re.sub(combined_pattern, '', bom_removed)\n",
        "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], stripped)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled).lower()\n",
        "    cleaned = (\" \".join(x for x in tok.tokenize(letters_only) if len(x) > 1)).strip()\n",
        "    cleaned = ''.join(k + k if sum(1 for i in g) > 1 else k for k, g in itertools.groupby(cleaned))\n",
        "    return cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldBo3QrDMXhS",
        "colab_type": "code",
        "outputId": "69ddab07-4995-42de-fa6f-a6cb12b80794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "data = p.read_csv(\"tweet.csv\", encoding=\"latin-1\", names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
        "data['clean_text'] = [getCleanTweet(text) for text in data['text']]\n",
        "data.dropna(inplace=True)\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "data.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   target      1600000 non-null  int64 \n",
            " 1   ids         1600000 non-null  int64 \n",
            " 2   date        1600000 non-null  object\n",
            " 3   flag        1600000 non-null  object\n",
            " 4   user        1600000 non-null  object\n",
            " 5   text        1600000 non-null  object\n",
            " 6   clean_text  1600000 non-null  object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 85.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNybGHINMXhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_values = data['clean_text'].values\n",
        "y_values = data['target'].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_values, y_values, test_size=0.10, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcl9Y42MMXht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create 4 models - \n",
        "# tf unigram,  \n",
        "# tf idf unigram, \n",
        "# tf unigram+bigram, \n",
        "# tf idf unigram+bigram\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#TF unigram\n",
        "\n",
        "tf_unigram = CountVectorizer(encoding='latin-1',binary=True,min_df = 5 )\n",
        "tf_idf_unigram = TfidfVectorizer(encoding='latin-1',use_idf=True,min_df = 5)\n",
        "tf_uni_bi = CountVectorizer(encoding='latin-1',binary=True, ngram_range=(1,2),min_df = 5)\n",
        "tf_idf_uni_bi = TfidfVectorizer(encoding='latin-1',use_idf=True, ngram_range=(1,2),min_df = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGAIptitr5RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = data.sample(frac =.2) \n",
        "\n",
        "x_values = sample['clean_text'].values\n",
        "y_values = sample['target'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_ChHkDtFu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_idf_vec = tf_idf_uni_bi.fit_transform(x_values)\n",
        "ts_idf_vec = tf_idf_uni_bi.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq5pwVWLKvqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10,80, 90],\n",
        "    'max_features': ['auto'],\n",
        "    'min_samples_leaf': [4],\n",
        "    'n_estimators': [50, 100, 200]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 2, n_jobs = -1, verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_AKQ0kq1nV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "398d6a83-e018-4c04-81db-bb767d3b0f9e"
      },
      "source": [
        "grid_search.fit(tr_idf_vec, y_values)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 143.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True], 'max_depth': [10, 80, 90],\n",
              "                         'max_features': ['auto'], 'min_samples_leaf': [4],\n",
              "                         'n_estimators': [50, 100, 200]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvu8as7-q8dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ecf261d9-13a2-494d-9876-4dfe79a90918"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 90,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 4,\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJk8I2zFbIAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1c7d818-8b5c-4b25-bbe7-eb003ff36477"
      },
      "source": [
        "grid_search.score(ts_idf_vec, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.776875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r00W-P5grC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1W8PA18rESF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}